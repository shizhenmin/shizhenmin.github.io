---
title: python爬虫
categories: python
tags: python 爬虫 技术
---

* content
{:toc}
## requests

### 安装

```bash
pip3 install requests
```



### 导入模块

```python
import requests
```



### 使用

```python
try:
    r=requests.get(url,timeout=30)#请求超时时间为30秒
    r.raise_for_status()#如果状态不是200，则引发异常
    r.encoding=r.apparent_encoding #配置编码
    return r.text
except:
    return "产生异常"
```

```python
def pachong():
    url = 'https://www.baidu.com/'
    header = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:75.0) Gecko/20100101 Firefox/75.0'
    }
    response = requests.get(url, headers=header)
    html = response.text
    bs = BeautifulSoup(html, 'html.parser')
```



### 导出文件



```python
# 以字符串形式输出
response = requests.get(url, headers=header)
html = response.text
with open('baidu.html', 'w', encoding='UTF-8') as f:
    f.write(html)

# 以二进制形式输出
html = response.content
with open('baidu.html', 'wb') as f:
    f.write(html)
```





## BeautifulSoup4

###　安装

```bash
pip3 install beautifulsoup4
pip3 install lxml
```



### 导入模块

```python
from bs4 import BeautifulSoup4
```



### 解析



```python
html_doc = """
<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title"><b>The Dormouse's story</b></p>

<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>

<p class="story">...</p>
"""

soup = BeautifulSoup(html_doc, 'lxml')
```

获取所有标签

```python
divs = soup.find_all('a')
for div in divs:
    print(div)
    print('*' * 60)
```

获取指定标签

```python
# 获取第一个标签
p = soup.p
p = soup.find('p')

div = soup.find_all('a')[1]
print(div)

soup.title
soup.title.name
soup.title.string
```

获取拥有指定属性的标签

```python
# 方法一
div = soup.find_all('a', class_="sister", id='link1')
print(div)

# 方法二
divs = soup.find_all('a', attrs={'class': 'sister', 'id': 'link1'})
print(div)

```

获取标签属性值

```python
alist = soup.find_all('a')
# 方法一：通过下标方式提取
for a in alist:
    href = a['href']
    print(href)

# 方法二：通过attrs参数提取
for a in alist:
    href = a.attrs['href']
    print(href)

# 方法二：通过get方法提取
for a in alist:
    href = a.get('href')
    print(href)
```

获取标签的文本

```python
# 获取标签的单个文本，这里 a 是一个列表
a = soup.find_all('a', id='link1')
print(a[0].strings)
print(a[0].get_text())

# 获取多个文本，会有 '\n'
p = soup.find_all('p', class_='story')[0]
text = list(p.strings)
print(text)

# 获取多个文本，去掉 '\n'
p = soup.find_all('p', class_='story')[0]
text = list(p.stripped_strings)
print(text)
```

获取标签子节点

```python
# 获取Tag的所有子节点，返回一个list
for i in soup.body.contents:
    print("###%s" % i)

# 获取Tag的所有子节点，返回一个生成器
for i in soup.body.children:
    print("###%s" % i)
```

























